# Assumption & Fallback Registry (Stage B.0)

All fallbacks/clipping/clamping/defaults/heuristics identified in Stage A and upstream audit. Authority: CAPOPM.pdf; requirements.txt; claim_table.md. No silent assumption may remain undocumented.

| ID | Description | File + Line Reference | Activation Condition | Downstream Impact | Distorted Claims/Metrics | Observability |
| --- | --- | --- | --- | --- | --- | --- |
| AF-01 | Stage1 behavioral weight clipping to [w_min, w_max] | `src/capopm/corrections/stage1_behavioral.py:62-115` (upstream audit `audit_investigation/UPSTREAM_PIPELINE_AUDIT.md:31-36`) | Herding/longshot weights exceed bounds | Alters effective counts; can suppress/extreme-weight signals | Regret metrics (B1, B3), coverage/calibration stability | Logged? Partial (weights not surfaced to audit); effectively silent in audit |
| AF-02 | Stage2 regime clamping for invalid alpha/beta in mixture | `src/capopm/corrections/stage2_structural.py:155-183` (upstream audit `audit_investigation/UPSTREAM_PIPELINE_AUDIT.md:31-36`) | Regime params nonpositive | Resets/clamps regimes, biasing regime weights toward priors | Regime entropy/max weight (B4), mixture means (A3, B3), regret comparisons | Silent; diagnostics not surfaced in audit |
| AF-03 | Calibration fallback to equal-mass binning | `src/capopm/metrics/calibration.py:124-145` (upstream audit `audit_investigation/UPSTREAM_PIPELINE_AUDIT.md:49-55`) | Nonempty bins < min_nonempty_bins or degenerate predictions | Changes ECE semantics; marks NOT_INTERPRETABLE but still produces values | Borderline flags (all experiments), any criteria relying on calibration status | Partially logged (ece_status), not surfaced in audit criteria |
| AF-04 | Projection epsilon clipping before simplex projection | `src/capopm/experiments/projection_utils.py:6-46` | Probabilities near 0/1 before projection | Biases distances and post-projection scores | B5 projection distance/delta scores; any arbitrage test | Silent; not recorded in audit outputs |
| AF-05 | Posterior log_score clamp to [eps, 1-eps] | `src/capopm/metrics/scoring.py:10-26` (upstream audit `audit_investigation/UPSTREAM_PIPELINE_AUDIT.md:48-55`) | p_hat near 0 or 1 | Limits log_score magnitude; reduces sensitivity to extreme forecasts | Regret_log metrics (A3, B1, B3), score deltas (B5) | Silent (no flag) |
| AF-06 | Structural prior surrogate (logit-based) replacing paper Phase 1 model | `src/capopm/structural_prior.py:18-70` (upstream audit `audit_investigation/UPSTREAM_PIPELINE_AUDIT.md:12-19`) | Always active (surrogate design) | Potential mismatch to CAPOPM.pdf Phase 1; biases priors/mixtures | Any claim depending on structural prior fidelity (A1, B1, B3, B4, B5) | Silent; no audit signal |
| AF-07 | Mean aggregation ignoring variance/CI | `src/capopm/experiments/runner.py:374-412` | Aggregation step across runs | Masks variability; overstated confidence in small-n regimes | All dominance/regret/entropy/coverage claims (A1, A3, B1, B3, B4) | Silent; only mean stored |
| AF-08 | Grid counting per scenario (`grid_points_observed=1`) | `src/capopm/experiments/audit.py:342-359` (SD-01 `audit_investigation/STAGE_A_CLOSURE_CHECKLIST.md:34-36`) | requires_grid criteria evaluated per scenario | Forces indeterminate results despite full sweep present | Grid_requirement criteria (A1, A3, B3, B4) | Logged via reason `grid_missing_for_claim` but no cross-scenario visibility |
| AF-09 | Conditional_on_violation auto-pass logic | `src/capopm/experiments/audit.py:332-418` | violation_strength <= 0 | Criteria pass without metric evaluation | B5 coherent cases, any conditional criteria | Silent aside from evaluated=false/pass=true |
| AF-10 | Alpha/beta positivity enforcement in likelihood update | `src/capopm/likelihood.py:12-20` | Invalid counts or params | Raises/guards; may drop runs if violated | All posterior-based metrics; could halt runs | Enforced (hard failure), not logged in audit |
